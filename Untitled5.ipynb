{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNy+Ip8rix9frzh/LDXWkz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karalius/Calculator/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp72u7kPmXOi",
        "outputId": "3ef7792f-9ade-4ecf-abc4-065a76473413"
      },
      "source": [
        "!pip install fake-useragent"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (0.1.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxDK9JKiXTaQ"
      },
      "source": [
        "from fake_useragent import UserAgent\n",
        "from lxml.html import fromstring\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLGKqxzKac6f"
      },
      "source": [
        "def get_proxies():\n",
        "    url = 'https://www.us-proxy.org/'\n",
        "    response = requests.get(url)\n",
        "    parser = fromstring(response.text)\n",
        "    proxies = set()\n",
        "    for i in parser.xpath('//tbody/tr')[:20]:\n",
        "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
        "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
        "            proxies.add(proxy)\n",
        "    return proxies"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu_u094bopE9"
      },
      "source": [
        "def replace_attr(html_doc: str, from_attr: str, to_attr: str) -> str:\n",
        "    soup = BeautifulSoup(html_doc.content, 'html.parser')\n",
        "    tags = soup(attrs={from_attr: True})\n",
        "\n",
        "    for tag in tags:\n",
        "        tag[to_attr] = tag[from_attr]\n",
        "        del tag[from_attr]\n",
        "\n",
        "    return soup"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCiRA686dJyo"
      },
      "source": [
        "def scrape_etsy(keywords: list, items_to_scrape: int) -> pd.DataFrame:\n",
        "    # input options: prints, painting, photography \n",
        "    average_items_per_page = 45\n",
        "    pages_to_scrape = math.ceil(items_to_scrape / average_items_per_page)\n",
        "    df_list = []\n",
        "\n",
        "    for key in keywords:\n",
        "        titles, prices, item_urls, img_urls = ([] for i in range(4))\n",
        "        adj_keyword = key.lower()\n",
        "        ua = UserAgent(use_cache_server=False)\n",
        "        proxies = get_proxies()\n",
        "\n",
        "        for page_no in range(1, pages_to_scrape + 1):\n",
        "            for proxy in proxies:\n",
        "                try:\n",
        "                    headers = {\n",
        "                        'authority': 'www.etsy.com',\n",
        "                        'sec-ch-ua': '^\\\\^Google',\n",
        "                        'sec-ch-ua-mobile': '?0',\n",
        "                        'upgrade-insecure-requests': '1',\n",
        "                        'user-agent': str(ua.random),\n",
        "                        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "                        'sec-fetch-site': 'same-origin',\n",
        "                        'sec-fetch-mode': 'navigate',\n",
        "                        'sec-fetch-user': '?1',\n",
        "                        'sec-fetch-dest': 'document',\n",
        "                        'referer': f'https://www.etsy.com/c/art-and-collectibles/{adj_keyword}?explicit=1&ship_to=US&ref=pagination&page={page_no-1}', # add changing referer\n",
        "                        'accept-language': 'en-US,en;q=0.9',\n",
        "                    }\n",
        "                    params = (\n",
        "                        ('explicit', '1'),\n",
        "                        ('ref', 'pagination'),\n",
        "                        ('page', f'{page_no}'),\n",
        "                    )\n",
        "                    page = requests.get(\n",
        "                        f\"https://www.etsy.com/c/art-and-collectibles/{adj_keyword}?explicit=1&ship_to=US&ref=pagination&page={page_no}\",\n",
        "                        headers = headers,\n",
        "                        params = params,\n",
        "                        proxies={\"http\": str(proxy), \"https\": str(proxy)}\n",
        "                    )\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    continue\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "            soup = replace_attr(page,'data-src', 'src')\n",
        "            \n",
        "            for value in soup.find_all('div', class_ = ['js-merch-stash-check-listing']):\n",
        "                if value.find(class_='strike-through'):\n",
        "                    value.unwrap()\n",
        "\n",
        "                titles.extend([title.get('title') for title in value.find_all('a')])\n",
        "                prices.extend([float(price.get_text().replace(',','')) for price in value.find_all('span', class_='currency-value')])\n",
        "                item_urls.extend([link.get('href') for link in value.find_all('a')])\n",
        "                img_urls.extend([pic.img['src'] for pic in value.find_all('div', class_='height-placeholder')])\n",
        "\n",
        "            time.sleep(np.random.uniform(0.4, 1.2)) # sleep\n",
        "\n",
        "        df_list.append(pd.DataFrame({\n",
        "        'category': adj_keyword[:items_to_scrape],\n",
        "        'title': titles[:items_to_scrape],\n",
        "        'price': prices[:items_to_scrape],\n",
        "        'item_url': item_urls[:items_to_scrape],\n",
        "        'img_url': img_urls[:items_to_scrape]\n",
        "    }))\n",
        "   \n",
        "    return pd.concat(df_list, ignore_index=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSABn_10_9h0"
      },
      "source": [
        "df = scrape_etsy(['painting', 'photography', 'prints'], 3000)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTPh2r7RdxhF",
        "outputId": "23a5a963-c879-48b2-813d-d2b33af6a7f9"
      },
      "source": [
        "import psycopg2\n",
        "\n",
        "# Connect to heroku, P.S. Hide this in local!\n",
        "sql_connection = psycopg2.connect(\n",
        "    database=\"dfvnovppbbq4rl\",\n",
        "    user=\"yntjjrygcmheyc\",\n",
        "    password=\"477cb32bc389caa14bd09da3c5c4a5ee704213bce0033af8db470ea5fbd2f5de\",\n",
        "    host=\"ec2-34-254-69-72.eu-west-1.compute.amazonaws.com\",\n",
        "    port=\"5432\"\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wom0G51aeEhv"
      },
      "source": [
        "cur = sql_connection.cursor()\n",
        "\n",
        "cur.execute('''\n",
        "CREATE TABLE IF NOT EXISTS categories (\n",
        "    id serial PRIMARY KEY,\n",
        "    category varchar(250)\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS items (\n",
        "    id serial PRIMARY KEY,\n",
        "    category_id int,\n",
        "    title varchar(250),\n",
        "    price float(2),\n",
        "    item_url varchar(500),\n",
        "    img_url varchar(500),\n",
        "    FOREIGN KEY (category_id) REFERENCES categories(id)\n",
        ");\n",
        "\n",
        "''')\n",
        "\n",
        "sql_connection.commit()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNxyCtweQ1z"
      },
      "source": [
        "cur = sql_connection.cursor()\n",
        "for i in df['category'].unique():\n",
        "    cur.execute(f\"INSERT INTO categories (category) VALUES ('{i}');\")\n",
        "sql_connection.commit()  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oaECTZheXZN",
        "outputId": "600054c0-5ff3-4005-d7a0-fc100e7194a3"
      },
      "source": [
        "cur.execute(\"SELECT * FROM categories;\")\n",
        "for row in cur.fetchall():\n",
        "    print(row)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'painting')\n",
            "(2, 'photography')\n",
            "(3, 'prints')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVS0YScieXuB"
      },
      "source": [
        "foreign_key_df = pd.DataFrame(df['category'].unique(), columns=['category']).reset_index().rename(columns={'index': 'category_id'})\n",
        "foreign_key_df['category_id'] = np.arange(1, len(foreign_key_df)+1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0a4u-iFekN4"
      },
      "source": [
        "items_df = pd.merge(\n",
        "    df,\n",
        "    foreign_key_df,\n",
        "    on='category'\n",
        ").drop(columns='category')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeB87rremMG"
      },
      "source": [
        "items_df.insert(0, 'category_id', items_df.pop('category_id'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaP54CmtfWmJ"
      },
      "source": [
        "sql_connection.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdnKLQjaesNF"
      },
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "conn = create_engine('postgresql://yntjjrygcmheyc:477cb32bc389caa14bd09da3c5c4a5ee704213bce0033af8db470ea5fbd2f5de@ec2-34-254-69-72.eu-west-1.compute.amazonaws.com:5432/dfvnovppbbq4rl')\n",
        "\n",
        "items_df.to_sql('items', conn, method='multi', if_exists='append', chunksize=10000, index=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEgLI7WGesqP"
      },
      "source": [
        "sql_connection = psycopg2.connect(\n",
        "    database=\"dfvnovppbbq4rl\",\n",
        "    user=\"yntjjrygcmheyc\",\n",
        "    password=\"477cb32bc389caa14bd09da3c5c4a5ee704213bce0033af8db470ea5fbd2f5de\",\n",
        "    host=\"ec2-34-254-69-72.eu-west-1.compute.amazonaws.com\",\n",
        "    port=\"5432\"\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-S7BfoGewL8"
      },
      "source": [
        "# connect psycopg2 again\n",
        "#cur = sql_connection.cursor()\n",
        "#cur.execute(\"SELECT * FROM items;\")\n",
        "#for row in cur.fetchall():\n",
        "#    print(row)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RevC0MQWex9Q"
      },
      "source": [
        "def get_csv():\n",
        "    from google.colab import files\n",
        "\n",
        "    cur = sql_connection.cursor()\n",
        "\n",
        "    s = \"SELECT items.id, categories.category, items.title, items.price, items.item_url, items.img_url FROM items JOIN categories ON categories.id = items.category_id ORDER BY id ASC\"\n",
        "\n",
        "    # Use the COPY function on the SQL we created above.\n",
        "    SQL_for_file_output = \"COPY ({0}) TO STDOUT WITH CSV HEADER\".format(s)\n",
        "\n",
        "    # Set up a variable to store our file path and name.\n",
        "\n",
        "    #t_path_n_file = \"C:\\Users\\37069\\Desktop\"\n",
        "\n",
        "    with open('etsy_data.csv', 'w') as f_output:\n",
        "        cur.copy_expert(SQL_for_file_output, f_output)\n",
        "\n",
        "    files.download('etsy_data.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EGi9OCjMezi1",
        "outputId": "ae8e93b5-acce-4112-e77e-85d2f90006b9"
      },
      "source": [
        "get_csv()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bd402083-24ab-4aa6-a548-716bd0ea47b9\", \"etsy_data.csv\", 3745856)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}